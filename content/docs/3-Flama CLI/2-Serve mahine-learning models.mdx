---
title: Serve machine-learning models
wip: true
---

import FlamaName from '@/components/FlamaName'
import PythonName from '@/components/PythonName'

The advantage of having flama CLI is the possibility of deploying an already trained-tested ML model as an API
ready to receive requests and return estimations.

Here we present the endpoints and documentation (SWAGER) auto-geneated, besides any other optional flag we might
be able to pass to uvicorn, either as parameter, option or ENV. Examples:

- FLAMA_APP
- FLAMA_MODEL
- FLAMA_URL
