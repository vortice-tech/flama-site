---
title: Add models to your App
wip: true
---

## Introduction

Once you have your ML models packaged in _flm_ format, they can be exposed as resources
of a Flama App. This is what constitutes what we refer to as a _Flama ML API_.

## Example of adding a TensorFlow model

```python
import typing

from flama import Flama

app = Flama()

app.models.add_model(
    path="/tf_model",
    model="path/to/your_model_file.flm",
    name="name_of_the_tf_model",
)
```

If you run this code, you will get an API with the following endpoints:

- `/tf_model`: Returns _resource_, i.e. the schema with `get_params()` (`GET`)
- `/tf_models/predict`: Returns prediction of model (`POST`)

## Example of adding a TensorFlow model

```python
import typing

from flama import Flama

app = Flama()

app.models.add_model(
    path="/sk_model",
    model="path/to/your_model_file.flm",
    name="name_of_the_sk_model",
)
```

- `/sk_model`: Returns _resource_, i.e. the schema with `get_params()` (`GET`)
- `/sk_models/predict`: Returns prediction of model (`POST`)

## Example of adding multiple ML models

```python
import typing

from flama import Flama

app = Flama()

app.models.add_model(
    path="/sk_model",
    model="path/to/your_model_file.flm",
    name="name_of_the_sk_model",
)

app.models.add_model(
    path="/tf_model",
    model="path/to/your_model_file.flm",
    name="name_of_the_tf_model",
)
```

- `/sk_model`: Returns _resource_, i.e. the schema with `get_params()` (`GET`)
- `/sk_models/predict`: Returns prediction of model (`POST`)
- `/tf_model`: Returns _resource_, i.e. the schema with `get_params()` (`GET`)
- `/tf_models/predict`: Returns prediction of model (`POST`)

**Remark**: Show SWAGER docs for all combinations
