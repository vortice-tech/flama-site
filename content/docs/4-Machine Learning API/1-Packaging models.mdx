---
title: Packaging models
wip: true
---

## Introduction

Any machine-learning model built using one of the mainstream data-science frameworks, e.g.
[Scikit-Learn](https://scikit-learn.org/stable/), [TensorFlow](https://www.tensorflow.org/) or
[PyTorch](https://pytorch.org/), can be served using <FlamaName/>. This, indeed, is what we have been explaining in the
previous sections on <FlamaName/> CLI commands [run](/docs/flama-cli/run), [serve](/docs/flama-cli/serve), and
[start](/docs/flama-cli/start). For this to happen, we needed either of the following two options:

- A model packaged as a binary file (**.flm** files)
- A model embedded in a <FlamaName/> App

The second option will be explained in detail in the following sections:
[add models](/docs/machine-learning-api/add-models), [model resource](/docs/machine-learning-api/model-resource), and
[model components](/docs/machine-learning-api/model-components). The first option (which is the one we are going to
discuss in what follows) requires us to save the models following a certain procedure. For the sake of convenience and
speeding up the process of integrating these models into an API,

<FlamaName /> comes with the functionality required to serialise and package them, automatically adding important
metadata which will make the resulting files operational seamlessly.

In this section we will introduce the methods required for this purpose:

- `flama.dump`
- `flama.load`

**Remark**: Flama's dump method uses optimal compression with the aim of making the process more efficient and faster.

**Remark 2**: The dump step can live completely out of any Flama API. Indeed, the natural place where you will be
running it will be at the model building stage (very likely in you Jupyter notebook).

## Example of serialising PyTorch models

```python
import flama
import torch

class Model(torch.nn.Module):
    def forward(self, x):
        return x + 10

with open("torch_model.flm", "wb") as f:
    flama.dump("pytorch", model, f)
```

## Example of serialising Scikit-Learn models

```python
import flama
from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(x_train, y_train)

with open("sk_model.flm", "wb") as f:
    flama.dump("sklearn", model, f)
```

## Example of serialising TensorFlow models

```python
import flama
import tensorflow as tf

model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10, activation='softmax')
])
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
model.fit(x_train, y_train, epochs=5)

with open("tf_model.flm", "wb") as f:
    flama.dump("tensorflow", model, f)
```
