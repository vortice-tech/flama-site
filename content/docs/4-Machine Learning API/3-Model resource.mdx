---
title: Model resources
wip: true
---

Thus far we have shown how to [package models](/docs/machine-learning-api/packaging-models) in order to
[add them](/docs/machine-learning-api/) to a <FlamaName/> App. The way in which ML models are added or what they
represent internally was not discussed in detail before, as that was not necessary for the purpose of previous sections.
However, it should be no surprise for us, _something_ happens under the hood when we add models. And, that "something"
is responsible for making the model object(s) accessible via HTTP request to certain URL(s). When we serve/add models
either by CLI **serve/start** or by using the syntax **app.models.add_model** we get the ability of interacting with the
model via the URL which is specified as parameter **path**. Here, interacting means:

- Obtaining a **JSON** representation of the model added, which contains all the parameters uniquely defining the model.
  We obtain this **JSON** representation by simply running a <Label color="green">GET</Label> request to the model URL, e.g.
  **http://127.0.0.1/sklearn/** for one of our examples.

- Obtaining predictions from the model added, which requires us to send the input data on which predictions will be run.
  We get such predictions via a <Label color="blue">POST</Label> requests with a data payload to the method predict of the model which is
  represented via the model-predict URL, e.g. **http://127.0.0.1/sklearn/predict/** for
  the same example.

This means, when we serve/add models, <FlamaName/> takes care of creating a **Resource** object per model automatically,
specifically a **ModelResource** object, which represents an API resource in the REST sense of the word. This object
defines the default way of interaction with the model itself by providing the methods just mentioned. A more thorough
discussion about the **Resource** class and its children classes can be found in [here](/docs/api-reference/resource).
However, the convenience of the method **add_models** might not be sufficient for your purposes for the following
reasons:

- You need to customise the default methods
- You need to define new methods for the resource

In what follows you will learn how to add model resources in a more customised way with the class **ModelResource**.

## The ModelResource class

The best way to learn how to implement your own model resources is by example, as we've been doing so far with previous
concepts. For this reason, we are going to re-implement the endpoints **/predict/** and **/inspect/** (which come by
default when using the tools seen before to serve/add models automatically) as a good starting point to showcase the
steps and ingredients required. With these two examples you will develop a better understanding of the _magic_ which
happens under the hood when using either the CLI **serve/start**, or the method **app.models.add_model**.
After these examples, you'll learn how to implement a custom method to be served as an endpoint, together with
the built-ins provided by default (actually, via the [metaclass](https://docs.python.org/3/reference/datamodel.html#metaclasses) **ModelResourceType**).

### Preamble

The first step (let's call it _preamble_) is to prepare our <FlamaName/> **app**, and all the ingredients needed to be
able to add custom model resources. This is exactly what you have here:

```python
# Standard import:
from flama import Flama

# New imports (not seen so far):
from flama.models import ModelResource, ModelResourceType
from flama.resources import resource_method

# Flama app instantiation:
app = Flama(
    title="Flama ML",
    version="0.1.0",
    description="Machine learning API using Flama ðŸ”¥",
)

# Model resources will be added here:
...

# In case we want to make it a runnable script:
if __name__ == "__main__":
    flama.run(flama_app="__main__:app", server_host="0.0.0.0", server_port=8080, server_reload=True)
```

As can be seen, there are three ingredients imported which we haven't seen yet, namely:

- **ModelResource**: This is a <FlamaName /> built-in class which derives from the most fundamental resource
  class **BaseResource**. These classes can be seen as the interface that any custom model class will need to adhere
  to. In case you're not familiar with the interface design pattern, we like the definition given by [RealPython](https://realpython.com/python-interface/):

  > At a high level, an interface acts as a blueprint for designing classes.
  > Like classes, interfaces define methods. Unlike classes, these methods are abstract.
  > An abstract method is one that the interface simply defines. It doesnâ€™t implement the methods.
  > This is done by classes, which then implement the interface and give concrete meaning to the interfaceâ€™s abstract methods.

- **ModelResourceType**: This is a <FlamaName /> built-in metaclass which derives from the most fundamental
  resource type metaclass **ResourceType**. The concept of metaclass is a bit less intuitive, and some highly
  recognised pythonists recommend to avoid them:

  > Metaclasses are deeper magic than 99% of users should ever worry about. If you wonder whether you need them,
  > you donâ€™t (the people who actually need them know with certainty that they need them, and donâ€™t need an
  > explanation about why).
  >
  > - Tim Peters

  We agree with such a claim, which is why you won't need to worry about them, apart from having to import the
  **ModelResourceType**, and use it as an argument when building your custom model class.

- **resource_method**: This is a <FlamaName /> built-in decorator which allows us to convert a given class method into
  an **app** endpoint, with the following main arguments:

  - **path**: Route path.
  - **methods**: HTTP methods available.
  - **name**: Route name

### Predict

```python
class MyModel(ModelResource, metaclass=ModelResourceType):
    name = "my_model"
    verbose_name = "My ML model"
    model_path = "path/to/your_model_file.flm"

    @resource_method("/predict", methods=["POST"], name="model-predict")
    def predict(self, x):
        return self.model.predict(x).tolist()
```

### Inspect

Explain the following meta-example:

```python
class MyModel(ModelResource, metaclass=ModelResourceType):
    name = "my_model"
    verbose_name = "My ML model"
    model_path = "path/to/your_model_file.flm"

    @resource_method("/inspect", methods=["GET"], name="model-inspect")
    def inspect(self) -> typing.Any:
        return self.model.get_params()
```

### Custom methods

Explain the following meta-example:

```python
class MyModel(ModelResource, metaclass=ModelResourceType):
    name = "my_model"
    verbose_name = "My ML model"
    model_path = "path/to/your_model_file.flm"

    @resource_method("/custom-method", methods=["GET"], name="model-custom-method")
    def custom_method(self):
        """
        summary:
            A custom method which returns the verbose name of the model.
        description:
            This is a more detailed description of the method itself.
            Here we can give all the details required and they will appear
            automatically in the auto-generated docs.
        responses:
            200:
                description: Verbose name of the ML model.
        """
        return {"name": self.verbose_name}
```

## Adding the resource

### Explicit

```python
class MySKLearnModel(ModelResource, metaclass=ModelResourceType):
    ...

app.models.add_model_resource(path="/model", resource=MySKLearnModel)
```

### Decorator

```python
@app.models.model("/model")
class MySKLearnModel(ModelResource, metaclass=ModelResourceType):
    ...
```

## Examples

As customary already, we will be using the example FLM files generated in the previous section, namely:

- [Scikit Learn model](/models/sklearn_model.flm)
- [TensorFlow model](/models/tensorflow_model.flm)
- [PyTorch model](/models/pytorch_model.flm)

### PyTorch

```python
class MyTorchModel(ModelResource, metaclass=ModelResourceType):
    name = "torch_model"
    verbose_name = "PyTorch Model"
    model_path = "path/to/your_model_file.flm"

    @resource_method("/info", methods=["GET"], name="model-info")
    def info(self):
        return {"name": self.verbose_name}
```

### Scikit-Learn

```python
class MySKLearnModel(ModelResource, metaclass=ModelResourceType):
    name = "sk_model"
    verbose_name = "SK-Learn Model"
    model_path = "path/to/your_model_file.flm"

    @resource_method("/info", methods=["GET"], name="model-info")
    def info(self):
        return {"name": self.verbose_name}
```

### TensorFlow

```python
class MySKLearnModel(ModelResource, metaclass=ModelResourceType):
    name = "tf_model"
    verbose_name = "TensorFlow Model"
    model_path = "path/to/your_model_file.flm"

    @resource_method("/info", methods=["GET"], name="model-info")
    def info(self):
        return {"name": self.verbose_name}
```

**Remark**: Show SWAGGER docs for all combinations
